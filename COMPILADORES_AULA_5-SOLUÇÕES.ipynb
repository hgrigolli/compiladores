{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COMPILADORES-AULA 5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucianosilva-github/compiladores/blob/main/COMPILADORES_AULA_5-SOLU%C3%87%C3%95ES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwxHf3E81Qyz"
      },
      "source": [
        "**COMPILADORES - AULA 05**\n",
        "\n",
        "**Prof. Luciano Silva**\n",
        "\n",
        "**OBJETIVOS DA AULA:**\n",
        "\n",
        "\n",
        "\n",
        "*   Entender e praticar com o algoritmo de análise sintática [ LALR(1) ] da ferramenta rply\n",
        "*   Entender e praticar com processo de detecção de erros de análise sintática\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbWUx55j1tLM",
        "outputId": "07837aa5-e36b-4825-a405-e1b479a9bf31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install rply"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rply\n",
            "  Downloading https://files.pythonhosted.org/packages/c0/7c/f66be9e75485ae6901ae77d8bdbc3c0e99ca748ab927b3e18205759bde09/rply-0.7.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from rply) (1.4.4)\n",
            "Installing collected packages: rply\n",
            "Successfully installed rply-0.7.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDogT1ytJrEt"
      },
      "source": [
        "**ALGORITMO DE ANÁLISE SINTÁTICA LALR(1)**\n",
        "\n",
        "Anteriormente, implementamos um analisador sintático completo para o comando de atribuição com expressões ariméticas envolvendo números inteiros sem sinal:\n",
        "\n",
        "\\<atrib\\>::= ID \"=\" \\<expression\\>\n",
        "\n",
        "\\<expression\\> ::= NUMBER\n",
        "\n",
        "       | \\<expression\\> \"+\" \\<expression\\>\n",
        " \n",
        "       | \\<expression\\> \"-\" \\<expression\\>\n",
        " \n",
        "       | \\<expression\\> \"*\" \\<expression\\>\n",
        " \n",
        "       | \\<expression\\> \"/\" \\<expression\\>\n",
        " \n",
        "       | \"(\" <expression> \")\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACSuZUyEJ2oQ"
      },
      "source": [
        "O primeiro passo foi implementar um analisador léxico para esta gramática, mostrado abaixo:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AohGQ2yWKDli"
      },
      "source": [
        "from rply import LexerGenerator\n",
        "\n",
        "lg = LexerGenerator()\n",
        "\n",
        "lg.add('ID', r'[a-zA-Z][a-zA-Z0-9]*')\n",
        "lg.add('EQUALS', r'=')\n",
        "lg.add('NUMBER', r'\\d+')\n",
        "lg.add('PLUS', r'\\+')\n",
        "lg.add('MINUS', r'-')\n",
        "lg.add('MUL', r'\\*')\n",
        "lg.add('DIV', r'/')\n",
        "lg.add('OPEN_PARENS', r'\\(')\n",
        "lg.add('CLOSE_PARENS', r'\\)')\n",
        "\n",
        "lg.ignore('\\s+')\n",
        "\n",
        "lexer = lg.build()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ricXOj1eH7Da"
      },
      "source": [
        "O segundo passo foi implementar as classes em Python para representar os nós da árvore sintática gerada pelo analisador sintático:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLcu5RuHDl6B"
      },
      "source": [
        "from rply.token import BaseBox\n",
        "\n",
        "class Number(BaseBox):\n",
        "    def __init__(self, value):\n",
        "        self.value = value\n",
        "\n",
        "    def eval(self):\n",
        "        return self.value\n",
        "\n",
        "class BinaryOp(BaseBox):\n",
        "    def __init__(self, left, right):\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "\n",
        "class Add(BinaryOp):\n",
        "    def eval(self):\n",
        "        return self.left.eval() + self.right.eval()\n",
        "\n",
        "class Sub(BinaryOp):\n",
        "    def eval(self):\n",
        "        return self.left.eval() - self.right.eval()\n",
        "\n",
        "class Mul(BinaryOp):\n",
        "    def eval(self):\n",
        "        return self.left.eval() * self.right.eval()\n",
        "\n",
        "class Div(BinaryOp):\n",
        "    def eval(self):\n",
        "        return self.left.eval() / self.right.eval()\n",
        "\n",
        "class Attrib(BaseBox):\n",
        "    def __init__(self, id, expression):\n",
        "        self.id = id\n",
        "        self.expression = expression"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OEfEiOCIVxX"
      },
      "source": [
        "Finalmente, foi implementado o analisado sintático para o comando de atribuição:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MB_wWwWEGcX"
      },
      "source": [
        "from rply import ParserGenerator\n",
        "\n",
        "pg = ParserGenerator(\n",
        "    # A list of all token names, accepted by the lexer.\n",
        "    ['NUMBER', 'OPEN_PARENS', 'CLOSE_PARENS',\n",
        "     'PLUS', 'MINUS', 'MUL', 'DIV','ID','EQUALS'\n",
        "    ],\n",
        "    # A list of precedence rules with ascending precedence, to\n",
        "    # disambiguate ambiguous production rules.\n",
        "    precedence=[\n",
        "        ('left', ['PLUS', 'MINUS']),\n",
        "        ('left', ['MUL', 'DIV'])    \n",
        "    ]\n",
        ")\n",
        "\n",
        "# regra <atrib>::= ID \"=\" <expression>\n",
        "\n",
        "@pg.production('atrib : ID EQUALS expression')\n",
        "def attrib(p):\n",
        "  return Attrib(p[0].getstr(),p[2])\n",
        "\n",
        "@pg.production('expression : NUMBER')\n",
        "def expression_number(p):\n",
        "    # p is a list of the pieces matched by the right hand side of the\n",
        "    # rule\n",
        "    return Number(int(p[0].getstr()))\n",
        "\n",
        "@pg.production('expression : OPEN_PARENS expression CLOSE_PARENS')\n",
        "def expression_parens(p):\n",
        "    return p[1]\n",
        "\n",
        "@pg.production('expression : expression PLUS expression')\n",
        "@pg.production('expression : expression MINUS expression')\n",
        "@pg.production('expression : expression MUL expression')\n",
        "@pg.production('expression : expression DIV expression')\n",
        "def expression_binop(p):\n",
        "    left = p[0]\n",
        "    right = p[2]\n",
        "    if p[1].gettokentype() == 'PLUS':\n",
        "        return Add(left, right)\n",
        "    elif p[1].gettokentype() == 'MINUS':\n",
        "        return Sub(left, right)\n",
        "    elif p[1].gettokentype() == 'MUL':\n",
        "        return Mul(left, right)\n",
        "    elif p[1].gettokentype() == 'DIV':\n",
        "        return Div(left, right)\n",
        "    else:\n",
        "        raise AssertionError('Oops, this should not be possible!')\n",
        "\n",
        "parser = pg.build()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I44QzYuen0ij"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaWSNLQeJG8F"
      },
      "source": [
        "Realizamos um teste com um comando de atribuição:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9H91s7fFWdB",
        "outputId": "d46711b7-bd79-4887-8baf-00730a8e7607",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "arvore=parser.parse(lexer.lex('x=1+2*3'))\n",
        "print(arvore)\n",
        "print(arvore.id)\n",
        "print(arvore.expression.eval())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<__main__.Attrib object at 0x7fafef9b7110>\n",
            "x\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp5zx9gB-92G"
      },
      "source": [
        "O algoritmo de análise sintática utilizado pela ferramenta rply é o LALR(1). Esta sigla significa que: \n",
        "\n",
        "*   o analisador irá olhar (**LOOK AHEAD**), no máximo, um token da entrada para decidir qual regra gramatical irá aplicar\n",
        "*   o analisador irá analisar a entrada da esquerda para a direita **(L)** e fará as reduções o mais à direita **(R)** possível. \n",
        "\n",
        "Para entender como esta algoritmo funciona, vamos utilizar a ferramenta online abaixo:\n",
        "\n",
        "https://fiona.dmcs.pl/tk/jsmachines.sourceforge.net/machines/lalr1.html\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smwo0iReAi_a"
      },
      "source": [
        "**EXERCÍCIO**\n",
        "\n",
        "Simular o algoritmo LALR(1) com a gramática fornecida no início desta aula, na ferramenta fornecida acima:\n",
        "\n",
        "\\<atrib\\>::= ID \"=\" \\<expression\\>\n",
        "\n",
        "\\<expression\\> ::= NUMBER\n",
        "\n",
        "   | \\<expression\\> \"+\" \\<expression\\>\n",
        " \n",
        "   | \\<expression\\> \"-\" \\<expression\\>\n",
        " \n",
        "   | \\<expression\\> \"*\" \\<expression\\>\n",
        " \n",
        "   | \\<expression\\> \"/\" \\<expression\\>\n",
        " \n",
        "   | \"(\" \\<expression\\> \")\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWVdPe3TCOIa"
      },
      "source": [
        "**DETECÇÃO DE ERROS NO PROCESSO DE ANÁLISE SINTÁTICA**\n",
        "\n",
        "Vamos, inicialmente, tentar fazer a análise sintática da seguinte entrada:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtKvqRzPCeha",
        "outputId": "b5b7aa95-8bfe-4954-ec75-cd4a7646de89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "arvore=parser.parse(lexer.lex('x=1+2*'))\n",
        "print(arvore)\n",
        "print(arvore.id)\n",
        "print(arvore.expression.eval())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParsingError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParsingError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-aef6d1cd9764>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marvore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x=1+2*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marvore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marvore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marvore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rply/parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, tokenizer, state)\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"For now, error_handler must raise.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mParsingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookahead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsourcepos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_production\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatestack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mParsingError\u001b[0m: (None, None)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0Rn_nnuCsZW"
      },
      "source": [
        "Observem que, nesta entrada, está faltando um segundo operando para a operação de multiplicação. Na ocorrência de um erro, por default, é gerada uma exceção do tipo **ParsingError**. Para tornar o processo mais amigável com o programador, podemos associar um detector de erros sintáticos ao nosso analisador sintático.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usevjMbxDw5z"
      },
      "source": [
        "from rply import ParserGenerator\n",
        "\n",
        "pg = ParserGenerator(\n",
        "    # A list of all token names, accepted by the lexer.\n",
        "    ['NUMBER', 'OPEN_PARENS', 'CLOSE_PARENS',\n",
        "     'PLUS', 'MINUS', 'MUL', 'DIV','ID','EQUALS'\n",
        "    ],\n",
        "    # A list of precedence rules with ascending precedence, to\n",
        "    # disambiguate ambiguous production rules.\n",
        "    precedence=[\n",
        "        ('left', ['PLUS', 'MINUS']),\n",
        "        ('left', ['MUL', 'DIV'])    \n",
        "    ]\n",
        ")\n",
        "\n",
        "@pg.error\n",
        "def error_handler(token):\n",
        "    raise ValueError(\"Token wasn't expected\")\n",
        "\n",
        "# regra <atrib>::= ID \"=\" <expression>\n",
        "\n",
        "@pg.production('atrib : ID EQUALS expression')\n",
        "def attrib(p):\n",
        "  return Attrib(p[0].getstr(),p[2])\n",
        "\n",
        "@pg.production('expression : NUMBER')\n",
        "def expression_number(p):\n",
        "    # p is a list of the pieces matched by the right hand side of the\n",
        "    # rule\n",
        "    return Number(int(p[0].getstr()))\n",
        "\n",
        "@pg.production('expression : OPEN_PARENS expression CLOSE_PARENS')\n",
        "def expression_parens(p):\n",
        "    return p[1]\n",
        "\n",
        "@pg.production('expression : expression PLUS expression')\n",
        "@pg.production('expression : expression MINUS expression')\n",
        "@pg.production('expression : expression MUL expression')\n",
        "@pg.production('expression : expression DIV expression')\n",
        "def expression_binop(p):\n",
        "    left = p[0]\n",
        "    right = p[2]\n",
        "    if p[1].gettokentype() == 'PLUS':\n",
        "        return Add(left, right)\n",
        "    elif p[1].gettokentype() == 'MINUS':\n",
        "        return Sub(left, right)\n",
        "    elif p[1].gettokentype() == 'MUL':\n",
        "        return Mul(left, right)\n",
        "    elif p[1].gettokentype() == 'DIV':\n",
        "        return Div(left, right)\n",
        "    else:\n",
        "        raise AssertionError('Oops, this should not be possible!')\n",
        "\n",
        "parser = pg.build()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a36ssGXEEJ08",
        "outputId": "bd028724-9f3b-4f77-af04-3beabeecee43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "arvore=parser.parse(lexer.lex('x=1+2*'))\n",
        "print(arvore)\n",
        "print(arvore.id)\n",
        "print(arvore.expression.eval())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-aef6d1cd9764>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marvore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x=1+2*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marvore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marvore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marvore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rply/parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, tokenizer, state)\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookahead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookahead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-274f57a8aa0a>\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(token)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mpg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0merror_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Token wasn't expected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# regra <atrib>::= ID \"=\" <expression>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Token wasn't expected"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WMu5EBNFseu"
      },
      "source": [
        "**EXERCÍCIO**\n",
        "\n",
        "Refatore o método error_handler(token) para imprimir todas as informações do token, para facilitar a intepretação do erro pelos programadores. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVb_BT5-F_ng"
      },
      "source": [
        "from rply import ParserGenerator\n",
        "\n",
        "pg = ParserGenerator(\n",
        "    # A list of all token names, accepted by the lexer.\n",
        "    ['NUMBER', 'OPEN_PARENS', 'CLOSE_PARENS',\n",
        "     'PLUS', 'MINUS', 'MUL', 'DIV','ID','EQUALS'\n",
        "    ],\n",
        "    # A list of precedence rules with ascending precedence, to\n",
        "    # disambiguate ambiguous production rules.\n",
        "    precedence=[\n",
        "        ('left', ['PLUS', 'MINUS']),\n",
        "        ('left', ['MUL', 'DIV'])    \n",
        "    ]\n",
        ")\n",
        "\n",
        "@pg.error\n",
        "def error_handler(token):\n",
        "    raise ValueError(\"Token wasn't expected: \"+token.name+\" \"+token.value+\" \"+str(token.source_pos))\n",
        "\n",
        "# regra <atrib>::= ID \"=\" <expression>\n",
        "\n",
        "@pg.production('atrib : ID EQUALS expression')\n",
        "def attrib(p):\n",
        "  return Attrib(p[0].getstr(),p[2])\n",
        "\n",
        "@pg.production('expression : NUMBER')\n",
        "def expression_number(p):\n",
        "    # p is a list of the pieces matched by the right hand side of the\n",
        "    # rule\n",
        "    return Number(int(p[0].getstr()))\n",
        "\n",
        "@pg.production('expression : OPEN_PARENS expression CLOSE_PARENS')\n",
        "def expression_parens(p):\n",
        "    return p[1]\n",
        "\n",
        "@pg.production('expression : expression PLUS expression')\n",
        "@pg.production('expression : expression MINUS expression')\n",
        "@pg.production('expression : expression MUL expression')\n",
        "@pg.production('expression : expression DIV expression')\n",
        "def expression_binop(p):\n",
        "    left = p[0]\n",
        "    right = p[2]\n",
        "    if p[1].gettokentype() == 'PLUS':\n",
        "        return Add(left, right)\n",
        "    elif p[1].gettokentype() == 'MINUS':\n",
        "        return Sub(left, right)\n",
        "    elif p[1].gettokentype() == 'MUL':\n",
        "        return Mul(left, right)\n",
        "    elif p[1].gettokentype() == 'DIV':\n",
        "        return Div(left, right)\n",
        "    else:\n",
        "        raise AssertionError('Oops, this should not be possible!')\n",
        "\n",
        "parser = pg.build()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYM2Fb8w5Arh",
        "outputId": "f95203c3-fc87-426c-b885-5e00fcb649cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "arvore=parser.parse(lexer.lex('x=1 2*3'))\n",
        "print(arvore)\n",
        "print(arvore.id)\n",
        "print(arvore.expression.eval())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5fad0bdf0966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marvore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x=1 2*3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marvore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marvore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marvore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rply/parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, tokenizer, state)\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookahead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookahead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-5c7122a876a8>\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(token)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mpg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0merror_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Token wasn't expected: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# regra <atrib>::= ID \"=\" <expression>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Token wasn't expected: NUMBER 2 SourcePosition(idx=4, lineno=1, colno=5)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym-pGbeCGD1v"
      },
      "source": [
        "**ATIVIDADE EAD**\n",
        "\n",
        "Refatore a implementação do analisador sintático para a linguagem TINY-C para incluir detecção de erros de compilação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92imM3KuGblM"
      },
      "source": [
        "#implemente sua solução a partir daqui."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}